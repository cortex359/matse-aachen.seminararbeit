{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "import json\n",
    "import sys\n",
    "import pathlib\n",
    "from matplotlib import pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import random\n",
    "from llm import send_prompt, sort_function\n",
    "from sort import quicksort, heapsort\n",
    "\n",
    "cp_data: dict[str, dict] = {}\n",
    "for file in pathlib.Path('data/shared-dataset/corona_pandemie').rglob('*.ipynb'):\n",
    "    with open(file) as f:\n",
    "        cp_data[file.stem.removeprefix('corona_pandemie_')] = json.load(f)\n",
    "\n",
    "cw_data: dict[str, dict] = {}\n",
    "for file in pathlib.Path('data/shared-dataset/corona_warn_app_analyse').rglob('*.ipynb'):\n",
    "    with open(file) as f:\n",
    "        cw_data[file.stem.removeprefix('corona_warn_app_analyse_')] = json.load(f)\n",
    "\n",
    "rp_data: dict[str, dict] = {}\n",
    "for file in pathlib.Path('data/shared-dataset/reproduktionszahl').rglob('*.ipynb'):\n",
    "    with open(file) as f:\n",
    "        rp_data[file.stem.removeprefix('reproduktionszahl_')] = json.load(f)\n",
    "\n",
    "wr_data: dict[str, dict] = {}\n",
    "for file in pathlib.Path('data/shared-dataset/werbeindustrie').rglob('*.ipynb'):\n",
    "    with open(file) as f:\n",
    "        wr_data[file.stem.removeprefix('werbeindustrie_')] = json.load(f)"
   ],
   "id": "9c90f31a61eceacc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def filter_images(data):\n",
    "    \"\"\"Sets the image data to None in the output of code cells.\"\"\"\n",
    "    for k, v in data.items():\n",
    "        for cell in v['cells']:\n",
    "            if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    "                for output in cell['outputs']:\n",
    "                    if 'data' in output and 'image/png' in output['data']:\n",
    "                        # remove image from data\n",
    "                        output['data']['image/png'] = None\n",
    "\n",
    "filter_images(cp_data)\n",
    "filter_images(cw_data)\n",
    "filter_images(rp_data)\n",
    "filter_images(wr_data)\n",
    "\n",
    "def filter_output_cells(data_array):\n",
    "    \"\"\"Removes the output of code cells.\"\"\"\n",
    "    data = deepcopy(data_array)\n",
    "    for k, v in data.items():\n",
    "        for i, cell in enumerate(v['cells']):\n",
    "            if cell['cell_type'] == 'code' and 'outputs' in cell:\n",
    "                #print(cell['outputs'])\n",
    "                data[k]['cells'][i]['outputs'] = []\n",
    "    return data"
   ],
   "id": "df8c97c3c6e4574a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "%autoreload 2\n",
    "from llm import send_prompt, sort_function\n",
    "\n",
    "def sort_f7(d1, d2):\n",
    "    systemprompt = \"\"\"You are provided with two Jupyter notebooks, 'Notebook A' and 'Notebook B,' each containing exercises and their corresponding solutions. Your task is to evaluate which notebook provides the better solutions based on the following criteria: correctness, accuracy, and completeness. A correct solution should provide the intended answer without errors, an accurate solution should be precise and well-reasoned, and a complete solution should contain solutions to all exercises.\n",
    "\n",
    "After evaluating both notebooks, output ONLY one of the following responses: 'Notebook A' or 'Notebook B.' Do not include any additional text—only return the name of the better notebook.\"\"\"\n",
    "\n",
    "    return sort_function(d1, d2, wr_data, systemprompt)\n",
    "\n",
    "check_idxs = list(wr_data.keys())\n",
    "random.shuffle(check_idxs)\n",
    "\n",
    "wr_data_sorted = heapsort(check_idxs, sort_f7)"
   ],
   "id": "2d3a57174425aea3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "werbeindustrie_points = pd.read_csv('data/shared-dataset/werbeindustrie_points.csv')\n",
    "\n",
    "df = werbeindustrie_points.loc[:, ['id', 'total_points']]\n",
    "\n",
    "df['inital_order'] = df['id'].map(lambda x: check_idxs.index(x))\n",
    "df['llm-heapsort_rank'] = df['id'].map(lambda x: wr_data_sorted[::1].index(x))\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "plt.title(\"Exercise: Werbeindustrie\\nLLM: Llama-3.3-70B-Instruct Heapsort\\nImages filtered\")\n",
    "sns.heatmap(df.corr(method='kendall'), annot=True)\n",
    "plt.show()"
   ],
   "id": "c5930af9268ee716",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = \"https://ai-jeyx77fjpq7ebdtm7701ai757489384058.services.ai.azure.com/models\" # os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT)\n",
    "\n",
    "model = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(os.environ[\"AZUREAI_ENDPOINT_KEY\"]),\n",
    "    model = \"DeepSeek-R1\"\n",
    ")\n",
    "\n",
    "\n",
    "response = model.complete(\n",
    "  messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    UserMessage(content=\"What are 3 things to visit in Seattle?\")\n",
    "  ],\n",
    "    model = \"DeepSeek-R1\",\n",
    "  max_tokens=1000\n",
    ")\n",
    "\n",
    "\n",
    "print(response)"
   ],
   "id": "f236b5675bd9205c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.core.exceptions import HttpResponseError\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "load_dotenv()\n",
    "\n",
    "endpoint = \"https://ai-jeyx77fjpq7ebdtm7701ai757489384058.services.ai.azure.com/models\" # os.getenv(\"AZURE_INFERENCE_SDK_ENDPOINT)\n",
    "\n",
    "def send_prompt(nb1: str, nb2: str, systemprompt: str = None, max_retries: int = 10) -> dict:\n",
    "    if not systemprompt:\n",
    "        systemprompt = \"\"\"You are provided with two Jupyter notebooks (Notebook A and Notebook B), each containing exercises with their solutions. Evaluate only the correctness and accuracy of the solutions—ignore code style, formatting, documentation, or any other factors. Determine which notebook contains more correct solutions and output ONLY \"Notebook A\" or \"Notebook B\".\"\"\"\n",
    "\n",
    "    data = {\n",
    "        \"model\": \"DeepSeek-R1\",  # \"Llama-3.3-70B-Instruct\"\n",
    "        \"messages\": [\n",
    "            SystemMessage(content=systemprompt),\n",
    "            UserMessage(content=f\"Notebook A: {nb1}\\n\\n\\nNotebook B: {nb2}\")\n",
    "        ],\n",
    "        \"max_tokens\": 4096,\n",
    "        \"temperature\": 0.1,\n",
    "    }\n",
    "\n",
    "    model = ChatCompletionsClient(\n",
    "        endpoint=endpoint,\n",
    "        credential=AzureKeyCredential(os.environ[\"AZUREAI_ENDPOINT_KEY\"]),\n",
    "        model = \"DeepSeek-R1\"\n",
    "    )\n",
    "\n",
    "    for attempt in range(1, max_retries + 1):\n",
    "        try:\n",
    "            response = model.complete(\n",
    "                messages=data[\"messages\"],\n",
    "                model = data[\"model\"],\n",
    "                max_tokens=data[\"max_tokens\"],\n",
    "                temperature=data[\"temperature\"]\n",
    "            )\n",
    "        except HttpResponseError as e:\n",
    "            print(f\"Request failed: {e}. Retrying in {2 ** attempt} seconds... (Attempt {attempt}/{max_retries})\")\n",
    "            time.sleep(2 ** attempt)\n",
    "            continue\n",
    "\n",
    "        print(f\"{response['usage']['prompt_tokens']} + {response['usage']['completion_tokens']}\")\n",
    "        if response and response['choices'][0]['finish_reason'] == 'stop':\n",
    "            return response\n",
    "\n",
    "    print(\"Max retries exceeded due to rate limiting.\")\n",
    "    return None"
   ],
   "id": "e76ed269a10c56a2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "send_prompt('2aaa', '1aaa')",
   "id": "65bc1ba4a372398e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def sort_function(d1, d2, dataset: dict, systemprompt: str, retry=10) -> bool:\n",
    "    if retry == 0:\n",
    "        print(\"Maximale Anzahl an Versuchen erreicht.\")\n",
    "        return False\n",
    "    response = send_prompt(str(dataset[d1]), str(dataset[d2]), systemprompt)\n",
    "    if response:\n",
    "        if \"choices\" in response and len(response[\"choices\"]) > 0:\n",
    "            msg = response[\"choices\"][0][\"message\"][\"content\"].strip()\n",
    "            print(msg)\n",
    "            if msg.endswith(\"Notebook A\"):\n",
    "                print(f\"{d1} > {d2}\")\n",
    "                return False\n",
    "            elif msg.endswith(\"Notebook B\"):\n",
    "                print(f\"{d1} < {d2}\")\n",
    "                return True\n",
    "            else:\n",
    "                # Implement a retry mechanism here\n",
    "                if retry > 1:\n",
    "                    print(f\"Antwort nicht eindeutig: {msg}. Retrying... {retry-1}\")\n",
    "                    return sort_function(d1, d2, dataset, systemprompt, retry=retry-1)\n",
    "                else:\n",
    "                    print(f\"{d1} == {d2}\")\n",
    "                    return False\n",
    "        else:\n",
    "            print(\"Unerwartetes Antwortformat:\", response)\n",
    "\n",
    "    wait_time = 2 ** (10-retry)\n",
    "    print(f\"Retrying... {wait_time}\")\n",
    "    time.sleep(wait_time)\n",
    "    return sort_function(d1, d2, dataset, systemprompt, retry=retry-1)\n",
    "\n",
    "def sort_f8(d1, d2):\n",
    "    systemprompt = \"\"\"You are provided with two Jupyter notebooks, 'Notebook A' and 'Notebook B,' each containing exercises and their corresponding solutions. Your task is to evaluate which notebook provides the better solutions based on the following criteria: correctness, accuracy, and completeness. A correct solution should provide the intended answer without errors, an accurate solution should be precise and well-reasoned, and a complete solution should contain solutions to all exercises.\n",
    "\n",
    "After evaluating both notebooks, output ONLY one of the following responses: 'Notebook A' or 'Notebook B.' Do not include any additional text—only return the name of the better notebook.\"\"\"\n",
    "\n",
    "    return sort_function(d1, d2, wr_data, systemprompt)\n",
    "\n",
    "check_idxs = list(wr_data.keys())\n",
    "random.shuffle(check_idxs)"
   ],
   "id": "2c9a15c9dc1616db",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "wr_data_sorted = heapsort(check_idxs, sort_f8)",
   "id": "30a121cfde9a564d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "werbeindustrie_points = pd.read_csv('data/shared-dataset/werbeindustrie_points.csv')\n",
    "\n",
    "df = werbeindustrie_points.loc[:, ['id', 'total_points']]\n",
    "\n",
    "df['inital_order'] = df['id'].map(lambda x: check_idxs.index(x))\n",
    "df['llm-heapsort_rank'] = df['id'].map(lambda x: wr_data_sorted[::1].index(x))\n",
    "df.set_index('id', inplace=True)\n",
    "\n",
    "plt.title(\"Exercise: Werbeindustrie\\nLLM: DeepSeek R1 Heapsort\\nImages filtered\")\n",
    "sns.heatmap(df.corr(method='kendall'), annot=True)\n",
    "plt.show()"
   ],
   "id": "d727c38cf162b864",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cp_data_filtered = filter_output_cells(cp_data)\n",
    "\n",
    "def sort_f1(d1, d2):\n",
    "    systemprompt = \"\"\"You are provided with two Jupyter notebooks, 'Notebook A' and 'Notebook B,' each containing exercises and their corresponding solutions. Your task is to evaluate which notebook provides the better solutions based on the following criteria: correctness, accuracy, and completeness. A correct solution should provide the intended answer without errors, an accurate solution should be precise and well-reasoned, and a complete solution should contain solutions to all exercises.\n",
    "\n",
    "After evaluating both notebooks, output ONLY one of the following responses: 'Notebook A' or 'Notebook B.' Do not include any additional text—only return the name of the better notebook.\"\"\"\n",
    "\n",
    "    return sort_function(d1, d2, cp_data_filtered, systemprompt)\n",
    "\n",
    "check_idxs = list(cp_data.keys())\n",
    "random.shuffle(check_idxs)\n",
    "\n",
    "cp_data_sorted = heapsort(check_idxs, sort_f1)"
   ],
   "id": "f5e541606c5acc49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "7df8d2530c247ded",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
